<h1>流量控制</h1>
<p>就是控制接口的访问流量大小，防止服务受不了这么多请求挂掉，不过这样用户体验就不好了。流量的合理控制可以达到让一部分用户得到良好的体验，但是另一些用户会直接无法使用某个功能，但是还是会觉得软件可以用的效果。Sentinel和hystrix都是这样的框架。</p>
<h1>熔断降级</h1>
<p>通过熔断和降级，就是流量控制的手段，能够保证服务不挂；</p>
<p>降级是接口能接受的请求已经达到了最大值，不在进行计算，但是会降级，执行一个函数，返回一个保底的回应。</p>
<p>熔断就是超时回应；</p>
<h1>流量的控制算法</h1>
<p>多少请求可以通过，怎么判断流量是不是太大了，直接通过检测服务器状态就可以解决这个问题，但是这个无法实时获取，而且获取了也无法判断服务是否是正常运行的。所以需要用别的办法，我们需要自己测试，设定规则，在规定的时间内，项目能够承受多少的流量。最多可以同时接受多少流量。根据测试的性能角度不同，给出的算法也不同。</p>
<ol>
<li>
<p>计数器算法</p>
<p>根据时间范围内检测</p>
<p>简单，可用于短信触发等，设置时间间隔，比如一秒内只能处理100个请求；</p>
<p>这样会有一个问题，在上一秒刚结束，和下一秒刚开始的时候，都发生了一百次请求，服务器的一秒间隔有自己的设置，但是客服的一秒是什么时候开始，和服务器是不同步的，在客户看起来，就好像一秒内可以请求二百次；</p>
<p>解决这个问题，可以在后端设置时间间隔的开始时间；或者用下面的办法；</p>
</li>
<li>
<p>滑动窗口算法</p>
<p>根据时间范围内检测</p>
<p>将时间大的时间间隔再细分一下，设置窗口大小为原来的时间间隔，窗口不断的滑动，这样就可以统计刚刚的时间间隔内发生的次数，而不会出现每个间隔都是隔离的局面；</p>
<p>每一次都是一个区间，而不是在特定的一秒或者一个时间内，区间的大小是固定的，所以每次都需要统计这个区间内的所有数量；</p>
<p>1，2都是根据时间检测的，第二个是根据当前时间统计时间范围，第一个是固定时间范围，但是客户端可不会按这个频率发送请求，所以第二种是合适的。</p>
</li>
<li>
<p>令牌捅</p>
<p>并发量测试</p>
<p>服务端设置一个捅，以恒定的速度往捅理放令牌，请求需要得到令牌才可以正常进行，如果没有请求就触发了限流，桶内的数量够多的话可以对应突击的流量；</p>
</li>
<li>
<p>漏桶限流算法</p>
<p>并发量测试</p>
<p>请求不断的被装入服务器的通内，服务端以恒定的速度去处理请求，如果捅满了会触发限流；</p>
</li>
</ol>
<h1>超高并发处理</h1>
<p>在很多高并发的场景下，秒杀，抢红包等，流量都会非常的高。</p>
<p>后端服务器能力是有限的，业务http服务器，一般没有nginx这样的专门服务器性能高，所以我们直接在nginx配置某个请求按照概率直接返回结果，请求不到服务层的Http。对于用户不是很大的场景可以不用，这样其实违背了抢，也包含了运气。</p>
<p>第二种是在业务层也采用限流，流量太高就直接拒绝，不会进行查询。</p>
<p>负载均衡多个服务器肯定是要做的。甚至有些场景，我们需要为这个超高请求提供特定的服务器，不让他影响正常的服务业务模块。</p>
<p>经过前面的操作，最终能够正常请求的服务器一定是可以应付这些请求的，就采用redis缓存一下就好了。</p>
