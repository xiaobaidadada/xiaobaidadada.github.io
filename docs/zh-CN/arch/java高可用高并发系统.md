高可用指的是，应用程序高度可用，服务器不至于死掉，但是没有说用户客户端是高度可用的。高并发在如今的网络环境语义下，指的是其实并不是物理上有很多的线程在并发，而是指的是多个业务在并发支持，但是其实可能此时正在排队，只是个对象，还没有成为一个线程，所以是业务高度并发。所以高并发高可用，会提高用户体验，但是无法提供好的用户体验，只是保证后端不死掉。

解决大量流量下的问题，实现高并发，高可用。如果公司有钱，硬件可以无限扩展购买，就不用考虑这么多了，如果我们要尽力节省硬件资源，那么就值得讨论一下了。下面我们从一个博客系统来说，怎么在硬件资源很有限的情况下，构建一个高可用，高并发系统。



1. 个人博客就是提供博客的，所以我们的后台，需要保存图片和文件，保存博客文字，我们还要统计多少人每天看到了多少次博客的统计，实现全文检索搜索等功能。起初项目流量不大，我们就用mysql，springboot，lucene就够了。每个用户都可以注册拥有自己的后台和博客，就像知乎和博客园那样。

2. 随着流量越来越大，看的人越来越多。我们把这个单体的springboot项目变成一个可变成多个独立个体的项目，我们将所有的缓存变量，从静态map，改为存到redis中，这样多个服务器就可以考虑使用同一个缓存数据源了。然后用nginx做一个负载均衡访问，我们启动了多个应用实例，这样就可以扩容多个应用程序在多个服务器上。我们现在还要独立为保存文件图片做一个服务器，独立出来。所以现在有三个服务主服务，redis服务，文件服务，主服务开启了多个实例，多个实例访问同一个redis和文件服务。

3. 这个时候，考虑到以后功能的递增，我们现在要考虑是采用云原生，还是分布式架构继续开发，云原生模型目前并不是主流，但是比起分布式架构要简单，所以我们使用分布式架构来继续开发。

4. 此时我们考虑到以后文件服务也要做分布式的多个实例，所以服务多了起来，我们开始用注册中心来保存这些服务实例，使用nocas吧，然后配置中心也有了，可以统一配置springboot的yml。

5. 随着文件多了起来，我们早期会自己做一个简易的分布式文件系统，不考虑使用阿里云这样的云服务，完全自己实现，如果以后扩展新能不好，可以搭建一个fastdfs。自己做的分布式文件系统，采用Zookeeper 来做协调。

6. 考虑到用户有大量博客文件导入的功能，为了不让服务挂掉，我们把导入的数据先保存到文件服务器上，然后发送多个消息到kafka上，独立提供一个服务来处理导入的事情，保证系统高度可用。

7. 随着数据量越来越大，lucnne单机版全文检索，不够用了，所以我们升级到es来提供服务。

8. 然后考虑到服务链变长后可能会出现等待链的情况浪费性能，所以我们对每个服务都加上Hystrix提供的熔断断流功能。

9. 目前主服务自己做身份校验，考虑到扩展性，我们使用getway网关替代nginx，做身份校验。

10. 为了避免网关会崩溃，我们设置多个网关ip接口，让前端先请求一个肯定不会挂的服务（说着玩的），负载获取一个随机的网关ip，然后以后一直请求这个ip的网关，还要做一个请求ip地址的默认值。

11. 在面对统计功能的时候，需要统计某个页面不同人数的访问量，这个时候可以利用布隆过滤器实现。

12. 有一些数据，我们观察到，用户登录信息，每次请求都会访问到，所以我们采用redis永不过期的方法处理，为了避免用户提供不存在的信息，造成我们去查询数据库，我们也是用布隆过滤器避免这一情况。对于低频率数据我们让他直接查缓存就好了，对于中等查询的业务，也要想着省内存，所以采用短期redis过期的方式。
13. 对于超大的表，我们还会采用分库分表的解决方案，这就涉及到了一个主键递增的问题，怎么解决看我的mysql文章。
14. 最后我们希望收集用户大量的操作信息，所以我们搭建一个大数据平台，将日志先保存到kafka，然后存进hadoop平台上的HIVE中。供我们数据分析。

。。。。这样基本就实现了一个能够保证在硬件不够的情况下，实现后台程序高度可用的软件。



在分布式系统中，又一个cap理论，cap代表着三个事件。

> 1. Consistency（一致性）：指的是多个服务之间的调用，数据返回是满足预期的。
> 2. Availability（可用性）：指的是某个服务是能够正常使用的。
> 3. Partition tolerance：指的是某个服务节点出现了意外。

这里我说是三个事件，而不是三个属性，因为对于分布式系统，属性并不是数据那样有可以修改的文字属性字段，而是一个事件指标。

这三个属性，最多有两个成立，原因就是1，2都是正向的，而3是负向的。这个理论的意义就是表达，一个系统不可能保证用户的高度体验，又能保证后端的每个服务都不出问题。所以我们一般牺牲用户体验，让用户提交后处于等待状态，实际的执行不会立即进行，或者拒绝用户的请求。典型的例子就是，四级考试我们都支持，抢位置的时候，卡得要死，他不会报错，也不会提示什么。这就是保证用户高度可用，只要流量请求到了，你就不卡，别人卡。但是最终的效果还是每个人都有卡的体验。服务器优先，比如腾讯或者支付宝这样的支付，或者秒杀业务场景，你提交信息，但是发现结果并不是立马出现的，而是提交后，前端一直去请求判断，后端有没有实际完成这个事情。或者直接提示服务不可用，而不是让用户在一直处于等待请求的页面。





