

当数据量越来越大的时候，怎么提高服务器的处理能力，资源利用最大化，是后端面临的问题，我其实也没真实接触过很大流量的实际项目，这里就根据自己所接触到的知识探讨一下可能会面临的问题。我们这里从一个网络请求，到返回给用户，分析请求的每个环节可以怎么尽可能的提高资源利用率。



# i/o与连接

对于一次网络请求，对于服务器来说，是进行了一次i/o请求的连接行为。i/o指的是所有程序与外部设备之间通信的行为，不管是磁盘文件，还是网络请求，都是读数据，写数据，都属于程序外部的，也就是内存外部的数据。

有一个前提是，现在的操作系统都是分时系统，就是说不断的轮询执行多个进程和线程，所以操作系统可以同时运行着多个程序。对于一个程序来说，我们开发的时候，可以认为操作系统所有的资源只为我们服务。

对于操作系统内核来说，进行一次i/o 只有两种方式，不管是linux还是windows都是这样，要么是线程堵塞，一直等待i/o完成，要么是非堵塞，立即返回文件描述符（如果引入面向对象，就是文件对象)，程序自己判断有没有完成读取。这两种方式都是等待i/o准备开始，等i/o准备开始后，还需要程序自己去读取文件的内容。这个判断i/o状态的方式是很重要的，很多进行i/o操作的函数（操作系统提供的，所有的系统，这些函数都是c），比如select，poll，epoll大家可以自行去了解，但是本质上只有操作系统只提供了前面这两种方式。



## 不同语言提供的i/o方式

1. java

java最常见的就是堵塞i/o，对于堵塞i/o，java提供了流的概念，一般只要是提供了流的概念就是堵塞型的i/o，当你的代码执行到读或者写i/o的时候，都是对流操作，会一直堵塞，底层会一直死循环的判断这个流能不能操作。用java 流式堵塞i/o实现的http库，也是堵塞型的接收网络请求，比如tomcat，所以这样的模型下，想要处理多个用户请求，只能用户请求一次，就单独为用户建立一个线程做处理。每个线程可以一直进行堵塞着不影响别的。

后面java又推出了 java nio 非堵塞模型，这种模型都会提供一个缓冲区或者channle通道的概念，还有回调函数，所有的i/o操作都不会堵塞，执行读或者写的i/o代码会直接执行，执行完以后的代码，要写在回调函数中，会用缓存变量的形式给回调函数。这样的方式对于用户来说自己的线程没有堵塞，这样实现的http服务器，不需要为每个请求都建立一个线程。其实底层肯定是有个线程池的，这个线程池对每个i/o立马返回的文件描述符进行判断，如果可以读了就调用响应的回调函数。比如netty就是对nio的封装，还有java框架现在流行的webflux，反应式框架都是这个。

对比一下这两种，第二种对于写代码编程来说是不友好的，因为不满足顺序执行，逻辑上会很抽象。但是第二种肯定比第一种对于多请求的并发性要好。

2. nodejs

nodejs 天然所有的i/o操作都是支持异步的，它的底层是事件循环，也是执行到i/o操作的时候底层的线程词不断遍历i/o有没有准备好，最后调用回调函数，但是js提供了 await和async 关键字，这俩关键字可以将异步的代码变成同步的形式，我可太喜欢这一点了。

但是nodejs主线程只能有一个，如果想有多个目前支持的不是很好，所以在并发能力上是不如java 使用nio的，因为java处理业务的逻辑代码也可以有多个线程。但是如果对于单核或者双核cpu机器来说，nodejs就完爆java的nio。采用异步的方式开发效率肯定还是nodejs高。

3. go

go 只有堵塞，但是go提供了goroutine ，这个东西并不是线程，也不是一般意义上的协程，协程只是复用同一个线程，比如Python。go的goroutine ，如果有多个，当执行到I/o的时候，他会先把整个goroutine 停掉，执行另一个goroutine ，甚至自己判断要不要使用多线程，我们可以认为，它的底层是没有异步i/o线程池这个行为的，他只会不断的切换goroutine ，并判断执行它，对于性能上，如果并发量小，且没有什么cpu操作的话，他只有一个线程不断的轮询切换着多个goroutine ，其实和nodejs的性能差不多了。但是go是二进制的，如果有cpu行为，他会更适合。



## 连接类型

分为短链接和长连接，短连接时类似http这样的，返回结果后就断开了。长连接是类似tcp或者websocket这样的，一直保持着连接。

如果是堵塞模型，长连接会一直肯定会一直占用着一个线程，这是很消耗资源的行为，一定要选择一个异步i/o模型的方式写代码。短连接，如果并发量很高，且没有什么cpu行为，如果逻辑只是判断，遍历，其实还不如底层http组装数据消耗cpu多，可以几乎认为不存在cpu行为，不是个for循环遍历一万次都不算cpu行为，这个也需要异步i/o，如果需要cpu行为，还是堵塞模型的好，需要单个多线程来做这些事情。就算是长连接，如果需要cpu行为，也需要堵塞i/o，有人会说，堵塞i/o在加上事件循环不好吗，请求都已经由自己的线程就没有必要再进行轮询了。**最好的办法是，将所有的cpu核心利用起来处理业务逻辑，底层默认几个线程一直遍历循环着。这个所有语言都可以实现。**；

因为我们是最大限度的利用资源，对于cpu型的请求，如果还用异步i/o就无法满足要求了，只能加服务器才能解决。这是由物理实际消耗量决定的。

我们可以得出：

> 请求数多，肯定需要异步i/o，请求数多，同时又需要cpu行为，必须将所有的核心利用起来，另外增加物理服务器。



# 接收连接

## nginx

接收连接，第一个一般都是nginx，nginx就是一个异步非堵塞的，支持webscoket和http，我们用它一般做代理转发，由于nginx是c语言写的，所以不存在gc，高级语言都有gc，而且数据类型精简，所以功能肯定比任何语言写的非堵塞i/o服务器都要好，所以nginx可承载的流量并发数量，在一个电脑上绝对可以大于本电脑上的其它全部之和。

只要服务器上的流量带宽足够大，完全可以使用这个作为分布式代理。

但是这个nginx可能会挂掉，如果是客户端是自己的程序，我们可以在自己的程序中，选择另一个ip的网关，如果是浏览器，对不起，由于js的限制，只能挂掉了，一般nginx挂了相当于主机挂了，重启吧。**nginx不可能由于流量挂掉，他只是转发代理**。



## DNS

如果有能力自己假设DNS服务器，我们就可以在用户请求域名的时候，就根据频率和使用情况给用户一个最好的ip结果。当然dns也不太可能挂掉。

如果有能力自己搭建dns服务器，对于任何类型的应用都会起到很大的帮助。可以做很多事情。



## CDN

可以提前将资源放到一个特定的服务器上，这些CDN服务器只是提供静态资源的，用户根据频率选择一个最近的，一般只有大型网站，或者云服务商才有能力做这个，而且很可能会使用到自己搭建的DNS。另外自己也可以靠nginx做一个小型的cdn服务器。如果客户端是自己做的，可以实现的途径更多。



# 代码接收分发

其实这一步并不是一定需要的，对于多服务的项目，通常会有一个网关，来做统一的身份认证，然后再进行转发。对于java来说有很多线程的组件，比如spring getway。

还有一个优点是，nginx代表着最大承受力，而项目到底能支持多少流量并做出限制，这里就可以做这一步，这就是限流。



# 核心业务开始处理

核心业务开始处理，这个时候可能会需要调用一下别的项目拿到结果，但是别的服务很可能并不能返回数据，所以我们要设置好这个异常处理，有一个最坏的结果处理，这个就叫熔断，通常就是超时未返回。java有一个很大的特点，就是任何一件小事都有很多框架，对于熔断这个操作就有很多框架。

对于超高的流量，我们可以改成异步i/o的服务器来提高能力。具体要使用什么类型，要看第一节i/i连接方面的套。

但服务器是有限的，我们并不能一直增加线程（堵塞模式），或者一直增加事件循环的事件数量（异步i/o)，如果流量持续升高，对于同步i/o来说每个用户都无法得到流畅的请求，对于异步i/o来说，很小部分还是流畅的，但是大部分都只能一直堵塞。所以这个时候可以使用概率，不仅要提供限流，还可以提供概率，直接返回错误结果，让用户再次自己主动请求，这属于让用户自己承担后果，表现的没有问题，但是就算是这样，如果流量超级大，还是会崩溃。如果采用了概率，就会导致一些场景，比如秒杀或者抢红包的时候，明明是自己先请求的，但是被拒绝了。



# 数据持久层

这是最后一步可以优化的点，一次操作，如果是查询数据库，对于磁盘来说肯定是耗时的，这样会延长一次请求的时间，导致线程持续累积数量增长。所以对于一些查询频率高的数据我们可以缓存到内存中。

如果数据转到内存中的类型是对象，或者项目本身是分布式的，有多个实例，这样可以使用redis。如果数据结构简单，用语言中的基本数据类型都可以保持，且不是分布式的，用项目变量就行了。



